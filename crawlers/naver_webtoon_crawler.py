# crawlers/naver_webtoon_crawler.py

import os
import time
import traceback
import asyncio
import aiohttp
import json
import sys
from tenacity import retry, stop_after_attempt, wait_exponential
from dotenv import load_dotenv

import config
from services.notification_service import send_completion_notifications
from .base_crawler import ContentCrawler
from database import get_cursor, create_standalone_connection, setup_database_standalone

load_dotenv()

HEADERS = config.CRAWLER_HEADERS
WEEKDAYS = config.WEEKDAYS

class NaverWebtoonCrawler(ContentCrawler):
    """ë„¤ì´ë²„ ì›¹íˆ° í¬ë¡¤ëŸ¬"""

    def __init__(self):
        super().__init__('naver_webtoon')

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
    async def _fetch_from_api(self, session, url):
        async with session.get(url, headers=HEADERS) as response:
            response.raise_for_status()
            data = await response.json()
            return data.get('titleList', data.get('list', []))

    async def _fetch_paginated_finished_candidates(self, session):
        all_candidates = {}
        page = 1
        MAX_PAGES = 150
        print("\n'ì™„ê²°/ì¥ê¸° íœ´ì¬ í›„ë³´' ëª©ë¡ í™•ë³´ë¥¼ ìœ„í•´ í˜ì´ì§€ë„¤ì´ì…˜ ìˆ˜ì§‘ ì‹œì‘...")
        while page <= MAX_PAGES:
            try:
                api_url = f"{config.NAVER_API_URL}/finished?order=UPDATE&page={page}&pageSize=100"
                webtoons_on_page = await self._fetch_from_api(session, api_url)
                if not webtoons_on_page:
                    print(f"  -> {page-1} í˜ì´ì§€ì—ì„œ ìˆ˜ì§‘ ì¢…ë£Œ (ë°ì´í„° ì—†ìŒ).")
                    break
                for webtoon in webtoons_on_page:
                    if webtoon['titleId'] not in all_candidates:
                        all_candidates[webtoon['titleId']] = webtoon
                print(f"  -> {page} í˜ì´ì§€ ìˆ˜ì§‘ ì™„ë£Œ. (í˜„ì¬ í›„ë³´êµ°: {len(all_candidates)}ê°œ)")
                page += 1
                await asyncio.sleep(0.1)
            except Exception as e:
                print(f"  -> {page} í˜ì´ì§€ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                break
        if page > MAX_PAGES:
            print(f"  -> ìµœëŒ€ {MAX_PAGES} í˜ì´ì§€ê¹Œì§€ ìˆ˜ì§‘í•˜ì—¬ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return all_candidates

    async def _fetch_paginated_weekday_data(self, session, api_day):
        all_candidates = {}
        page = 1
        MAX_PAGES = 50  # You can adjust this if needed
        # print(f"\n'{api_day}' ìš”ì¼ ì›¹íˆ° ëª©ë¡ í™•ë³´ë¥¼ ìœ„í•´ í˜ì´ì§€ë„¤ì´ì…˜ ìˆ˜ì§‘ ì‹œì‘...")
        while page <= MAX_PAGES:
            try:
                api_url = f"{config.NAVER_API_URL}/weekday?week={api_day}&page={page}&pageSize=100"
                webtoons_on_page = await self._fetch_from_api(session, api_url)
                if not webtoons_on_page:
                    # print(f"  -> {api_day}: {page-1} í˜ì´ì§€ì—ì„œ ìˆ˜ì§‘ ì¢…ë£Œ (ë°ì´í„° ì—†ìŒ).")
                    break
                for webtoon in webtoons_on_page:
                    if webtoon['titleId'] not in all_candidates:
                        all_candidates[webtoon['titleId']] = webtoon
                # print(f"  -> {api_day}: {page} í˜ì´ì§€ ìˆ˜ì§‘ ì™„ë£Œ. (í˜„ì¬ í›„ë³´êµ°: {len(all_candidates)}ê°œ)")
                page += 1
                await asyncio.sleep(0.1)
            except Exception as e:
                # print(f"  -> {api_day}: {page} í˜ì´ì§€ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                break
        # if page > MAX_PAGES:
        #     print(f"  -> {api_day}: ìµœëŒ€ {MAX_PAGES} í˜ì´ì§€ê¹Œì§€ ìˆ˜ì§‘í•˜ì—¬ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return all_candidates

    async def fetch_all_data(self):
        print("ë„¤ì´ë²„ ì›¹íˆ° ì„œë²„ì—ì„œ ì˜¤ëŠ˜ì˜ ìµœì‹  ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤...")
        async with aiohttp.ClientSession() as session:
            ongoing_tasks = [self._fetch_paginated_weekday_data(session, api_day) for api_day in WEEKDAYS.keys()]
            ongoing_results = await asyncio.gather(*ongoing_tasks, return_exceptions=True)
            finished_candidates = await self._fetch_paginated_finished_candidates(session)

        print("\n--- ë°ì´í„° ìˆ˜ì§‘ ê²°ê³¼ ---")
        naver_ongoing_today, naver_hiatus_today, naver_finished_today = {}, {}, {}
        api_days = list(WEEKDAYS.keys())
        for i, result in enumerate(ongoing_results):
            day_key = api_days[i]
            if isinstance(result, Exception):
                print(f"âŒ '{day_key}'ìš”ì¼ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {result}")
                continue

            for webtoon in result.values():
                titleId = webtoon['titleId']

                if titleId not in naver_ongoing_today:
                    naver_ongoing_today[titleId] = webtoon
                    naver_ongoing_today[titleId]['normalized_weekdays'] = set()

                naver_ongoing_today[titleId]['normalized_weekdays'].add(WEEKDAYS[day_key])

                if webtoon.get('rest', False):
                    naver_hiatus_today[titleId] = webtoon

        print("  -> ìˆ˜ì§‘ëœ ìš”ì¼ ì •ë³´ë¥¼ listë¡œ ë³€í™˜í•©ë‹ˆë‹¤...")
        for webtoon in naver_ongoing_today.values():
            webtoon['normalized_weekdays'] = list(webtoon['normalized_weekdays'])

        for tid, data in finished_candidates.items():
            if tid not in naver_ongoing_today and tid not in naver_hiatus_today:
                if data.get('rest', False):
                    naver_hiatus_today[tid] = data
                else:
                    naver_finished_today[tid] = data

        all_naver_webtoons_today = {**naver_finished_today, **naver_hiatus_today, **naver_ongoing_today}
        print(f"ì˜¤ëŠ˜ì ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: ì´ {len(all_naver_webtoons_today)}ê°œ ê³ ìœ  ì›¹íˆ° í™•ì¸")
        return naver_ongoing_today, naver_hiatus_today, naver_finished_today, all_naver_webtoons_today

    def synchronize_database(self, conn, all_naver_webtoons_today, naver_ongoing_today, naver_hiatus_today, naver_finished_today):
        print("\nDBë¥¼ ì˜¤ëŠ˜ì˜ ìµœì‹  ìƒíƒœë¡œ ì „ì²´ ë™ê¸°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        cursor = get_cursor(conn)
        cursor.execute("SELECT content_id FROM contents WHERE source = %s", (self.source_name,))
        db_existing_ids = {row['content_id'] for row in cursor.fetchall()}
        updates, inserts = [], []

        for content_id, webtoon_data in all_naver_webtoons_today.items():
            status = ''
            if content_id in naver_finished_today: status = 'ì™„ê²°'
            elif content_id in naver_hiatus_today: status = 'íœ´ì¬'
            elif content_id in naver_ongoing_today: status = 'ì—°ì¬ì¤‘'
            else: continue

            author = webtoon_data.get('author')
            meta_data = {
                "common": {
                    "authors": [author] if author else [],
                    "thumbnail_url": None
                },
                "attributes": {
                    "weekdays": webtoon_data.get('normalized_weekdays', [])
                }
            }

            if content_id in db_existing_ids:
                record = ('webtoon', webtoon_data['titleName'], status, json.dumps(meta_data), content_id, self.source_name)
                updates.append(record)
            else:
                record = (content_id, self.source_name, 'webtoon', webtoon_data['titleName'], status, json.dumps(meta_data))
                inserts.append(record)

        if updates:
            cursor.executemany("UPDATE contents SET content_type=%s, title=%s, status=%s, meta=%s WHERE content_id=%s AND source=%s", updates)
            print(f"{len(updates)}ê°œ ì›¹íˆ° ì •ë³´ ì—…ë°ì´íŠ¸ ì™„ë£Œ.")

        if inserts:
            # === ğŸš¨ [ë²„ê·¸ ìˆ˜ì •] INSERT ë¦¬ìŠ¤íŠ¸ì˜ ì ì¬ì  ì¤‘ë³µ ì œê±° ===
            seen_keys = set()
            unique_inserts = []
            for record in inserts:
                key = (record[0], record[1]) # (content_id, source)
                if key not in seen_keys:
                    unique_inserts.append(record)
                    seen_keys.add(key)
            # =======================================================

            cursor.executemany("INSERT INTO contents (content_id, source, content_type, title, status, meta) VALUES (%s, %s, %s, %s, %s, %s)", unique_inserts) # ğŸ‘ˆ unique_inserts ì‚¬ìš©
            print(f"{len(unique_inserts)}ê°œ ì‹ ê·œ ì›¹íˆ° DB ì¶”ê°€ ì™„ë£Œ. (ì¤‘ë³µ {len(inserts) - len(unique_inserts)}ê°œ ì œê±°)")

        conn.commit()
        cursor.close()
        print("DB ë™ê¸°í™” ì™„ë£Œ.")
        return len(unique_inserts)

    async def run_daily_check(self, conn):
        print("LOG: run_daily_check started.")
        cursor = get_cursor(conn)
        print(f"=== {self.source_name} ì¼ì¼ ì ê²€ ì‹œì‘ ===")
        cursor.execute("SELECT content_id, status FROM contents WHERE source = %s", (self.source_name,))
        db_state_before_sync = {row['content_id']: row['status'] for row in cursor.fetchall()}
        cursor.close()
        print("LOG: Initial database state loaded.")

        ongoing, hiatus, finished, all_content = await self.fetch_all_data()
        print("LOG: Data fetched from API.")

        newly_completed_ids = {cid for cid, s in db_state_before_sync.items() if s in ('ì—°ì¬ì¤‘', 'íœ´ì¬') and cid in finished}
        print(f"LOG: Found {len(newly_completed_ids)} newly completed items.")

        details, notified = send_completion_notifications(get_cursor(conn), newly_completed_ids, all_content, self.source_name)
        print("LOG: Notification service executed.")

        added = self.synchronize_database(conn, all_content, ongoing, hiatus, finished)
        print("LOG: Database synchronization executed.")

        print("\n=== ì¼ì¼ ì ê²€ ì™„ë£Œ ===")
        return added, details, notified

if __name__ == '__main__':
    print("==========================================")
    print("  CRAWLER SCRIPT STARTED (STANDALONE)")
    print("==========================================")
    start_time = time.time()
    report = {'status': 'ì„±ê³µ'}
    db_conn = None
    CRAWLER_DISPLAY_NAME = "ë„¤ì´ë²„ ì›¹íˆ°"

    try:
        # [ì‚­ì œ] í¬ë¡¤ëŸ¬ê°€ DB ì…‹ì—…ì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” ìœ„í—˜í•œ ì½”ë“œ ì œê±°
        # print("LOG: Calling setup_database_standalone()...")
        # setup_database_standalone()
        # print("LOG: setup_database_standalone() finished.")

        print("LOG: Calling create_standalone_connection()...")
        db_conn = create_standalone_connection()
        print("LOG: create_standalone_connection() finished.")

        crawler = NaverWebtoonCrawler()
        print("LOG: NaverWebtoonCrawler instance created.")

        print("LOG: Calling asyncio.run(crawler.run_daily_check())...")
        new_contents, completed_details, total_notified = asyncio.run(crawler.run_daily_check(db_conn))
        print("LOG: asyncio.run(crawler.run_daily_check()) finished.")

        report.update({'new_webtoons': new_contents, 'completed_details': completed_details, 'total_notified': total_notified})

    except Exception as e:
        print(f"ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}")
        report['status'] = 'ì‹¤íŒ¨'
        report['error_message'] = traceback.format_exc()

    finally:
        if db_conn:
            print("LOG: Closing database connection.")
            db_conn.close()

        report['duration'] = time.time() - start_time

        # === ğŸš¨ [ë¦¬íŒ©í† ë§] ë©”ì¼ ë°œì†¡ ëŒ€ì‹  DBì— ë³´ê³ ì„œ ì €ì¥ ===
        report_conn = None
        try:
            report_conn = create_standalone_connection()
            report_cursor = get_cursor(report_conn)
            print(f"LOG: Saving report to 'daily_crawler_reports' table...")
            report_cursor.execute(
                """
                INSERT INTO daily_crawler_reports (crawler_name, status, report_data)
                VALUES (%s, %s, %s)
                """,
                (CRAWLER_DISPLAY_NAME, report['status'], json.dumps(report))
            )
            report_conn.commit()
            report_cursor.close()
            print("LOG: Report saved successfully.")
        except Exception as report_e:
            print(f"FATAL: [ì‹¤íŒ¨] ë³´ê³ ì„œ DB ì €ì¥ ì‹¤íŒ¨: {report_e}", file=sys.stderr)
        finally:
            if report_conn:
                report_conn.close()
        # =================================================

        print("==========================================")
        print("  CRAWLER SCRIPT FINISHED")
        print("==========================================")

        if report['status'] == 'ì‹¤íŒ¨':
            sys.exit(1)
